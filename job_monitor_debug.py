"""
JOB MONITOR - VERSIÃ“N DEBUG
Prueba de scraping con informaciÃ³n detallada
"""

import requests
from bs4 import BeautifulSoup
from datetime import datetime

# ============================================================================
# HERRAMIENTAS DE DEBUG
# ============================================================================

class DebugScraper:
    """Scraper con informaciÃ³n detallada para debugging"""
    
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    
    def test_indeed(self, titulo_busqueda):
        """Prueba Indeed con informaciÃ³n detallada"""
        print("\n" + "="*70)
        print(f"ğŸ§ª PROBANDO INDEED")
        print("="*70 + "\n")
        
        try:
            url = "https://es.indeed.com/jobs"
            parametros = {
                "q": titulo_busqueda,
                "l": "Spain",
                "radius": "0",
                "jt": "fulltime"
            }
            
            print(f"ğŸ“ URL base: {url}")
            print(f"ğŸ” ParÃ¡metros:")
            for key, value in parametros.items():
                print(f"   â€¢ {key}: {value}")
            
            print(f"\nğŸ“¤ Enviando peticiÃ³n...\n")
            
            response = requests.get(
                url,
                params=parametros,
                headers=self.headers,
                timeout=10
            )
            
            print(f"ğŸ“¥ Respuesta recibida:")
            print(f"   â€¢ Status Code: {response.status_code}")
            print(f"   â€¢ Content-Type: {response.headers.get('content-type', 'N/A')}")
            print(f"   â€¢ TamaÃ±o: {len(response.content)} bytes")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, "html.parser")
                
                # Buscar diferentes selectores
                print(f"\nğŸ” Buscando ofertas con diferentes selectores:\n")
                
                # Selector 1
                jobs1 = soup.find_all("div", class_="job_seen_beacon")
                print(f"   â€¢ Selector 1 (job_seen_beacon): {len(jobs1)} resultados")
                
                # Selector 2
                jobs2 = soup.find_all("div", class_="job-tile")
                print(f"   â€¢ Selector 2 (job-tile): {len(jobs2)} resultados")
                
                # Selector 3
                jobs3 = soup.find_all("article")
                print(f"   â€¢ Selector 3 (article): {len(jobs3)} resultados")
                
                # Selector 4
                jobs4 = soup.find_all("li", class_="css-5lfssm")
                print(f"   â€¢ Selector 4 (li css-5lfssm): {len(jobs4)} resultados")
                
                # Buscar todos los divs con clase que contenga "job"
                jobs_all = soup.find_all("div", class_=lambda x: x and "job" in x.lower())
                print(f"   â€¢ Selector genÃ©rico (contiene 'job'): {len(jobs_all)} resultados")
                
                # Guardar HTML para inspecciÃ³n
                with open("debug_indeed.html", "w", encoding="utf-8") as f:
                    f.write(response.text[:5000])  # Primeros 5000 caracteres
                print(f"\nğŸ“„ HTML guardado en: debug_indeed.html")
                
                # Mostrar estructura bÃ¡sica
                print(f"\nğŸ—ï¸ Estructura de la pÃ¡gina:")
                title = soup.find("title")
                print(f"   â€¢ TÃ­tulo: {title.text if title else 'N/A'}")
                
                h1 = soup.find("h1")
                print(f"   â€¢ H1: {h1.text if h1 else 'N/A'}")
                
                # Verificar si hay errores/bloques
                if "Please enable javascript" in response.text or "Enable JavaScript" in response.text:
                    print(f"\nâš ï¸ PROBLEMA: Indeed requiere JavaScript")
                    print(f"   SoluciÃ³n: Usar Selenium o API alternativa")
                    return False
                
                if response.status_code == 403:
                    print(f"\nâš ï¸ PROBLEMA: Acceso denegado (403)")
                    print(f"   SoluciÃ³n: Indeed bloquea este User-Agent")
                    return False
                
                if len(jobs1) == 0 and len(jobs2) == 0 and len(jobs3) == 0:
                    print(f"\nâš ï¸ PROBLEMA: No se encontraron ofertas")
                    print(f"   Posibles causas:")
                    print(f"   1. Los selectores CSS han cambiado")
                    print(f"   2. Indeed bloqueÃ³ la peticiÃ³n")
                    print(f"   3. No hay ofertas para esta bÃºsqueda")
                    return False
                
                return True
            
            else:
                print(f"\nâŒ Error HTTP: {response.status_code}")
                if response.status_code == 403:
                    print("   SoluciÃ³n: Aumentar delay o cambiar headers")
                elif response.status_code == 429:
                    print("   SoluciÃ³n: Too many requests, esperar mÃ¡s tiempo")
                return False
        
        except requests.exceptions.Timeout:
            print(f"âŒ ERROR: Timeout (conexiÃ³n muy lenta)")
            return False
        except Exception as e:
            print(f"âŒ ERROR: {e}")
            return False
    
    def test_infojobs(self, titulo_busqueda):
        """Prueba InfoJobs con informaciÃ³n detallada"""
        print("\n" + "="*70)
        print(f"ğŸ§ª PROBANDO INFOJOBS")
        print("="*70 + "\n")
        
        try:
            url = "https://www.infojobs.net/search"
            parametros = {
                "q": titulo_busqueda,
                "c": "47"
            }
            
            print(f"ğŸ“ URL base: {url}")
            print(f"ğŸ” ParÃ¡metros:")
            for key, value in parametros.items():
                print(f"   â€¢ {key}: {value}")
            
            print(f"\nğŸ“¤ Enviando peticiÃ³n...\n")
            
            response = requests.get(
                url,
                params=parametros,
                headers=self.headers,
                timeout=10
            )
            
            print(f"ğŸ“¥ Respuesta recibida:")
            print(f"   â€¢ Status Code: {response.status_code}")
            print(f"   â€¢ TamaÃ±o: {len(response.content)} bytes")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, "html.parser")
                
                print(f"\nğŸ” Buscando ofertas:\n")
                
                # Selector 1
                jobs1 = soup.find_all("article", class_="offer")
                print(f"   â€¢ Selector 1 (article.offer): {len(jobs1)} resultados")
                
                # Selector 2
                jobs2 = soup.find_all("div", class_="offer")
                print(f"   â€¢ Selector 2 (div.offer): {len(jobs2)} resultados")
                
                # Selector 3
                jobs3 = soup.find_all("article")
                print(f"   â€¢ Selector 3 (article genÃ©rico): {len(jobs3)} resultados")
                
                # Guardar HTML
                with open("debug_infojobs.html", "w", encoding="utf-8") as f:
                    f.write(response.text[:5000])
                print(f"\nğŸ“„ HTML guardado en: debug_infojobs.html")
                
                if len(jobs1) == 0 and len(jobs2) == 0:
                    print(f"\nâš ï¸ PROBLEMA: No se encontraron ofertas")
                    return False
                
                return True
            
            else:
                print(f"\nâŒ Error HTTP: {response.status_code}")
                return False
        
        except Exception as e:
            print(f"âŒ ERROR: {e}")
            return False
    
    def test_computrabajo(self, titulo_busqueda):
        """Prueba Computrabajo con informaciÃ³n detallada"""
        print("\n" + "="*70)
        print(f"ğŸ§ª PROBANDO COMPUTRABAJO")
        print("="*70 + "\n")
        
        try:
            url = "https://www.computrabajo.com/search/jobs"
            parametros = {
                "q": titulo_busqueda,
                "location": "Spain"
            }
            
            print(f"ğŸ“ URL base: {url}")
            print(f"ğŸ” ParÃ¡metros:")
            for key, value in parametros.items():
                print(f"   â€¢ {key}: {value}")
            
            print(f"\nğŸ“¤ Enviando peticiÃ³n...\n")
            
            response = requests.get(
                url,
                params=parametros,
                headers=self.headers,
                timeout=10
            )
            
            print(f"ğŸ“¥ Respuesta recibida:")
            print(f"   â€¢ Status Code: {response.status_code}")
            print(f"   â€¢ TamaÃ±o: {len(response.content)} bytes")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, "html.parser")
                
                print(f"\nğŸ” Buscando ofertas:\n")
                
                # Selector 1
                jobs1 = soup.find_all("div", class_="offer-item")
                print(f"   â€¢ Selector 1 (offer-item): {len(jobs1)} resultados")
                
                # Selector 2
                jobs2 = soup.find_all("div", class_="job")
                print(f"   â€¢ Selector 2 (job): {len(jobs2)} resultados")
                
                # Guardar HTML
                with open("debug_computrabajo.html", "w", encoding="utf-8") as f:
                    f.write(response.text[:5000])
                print(f"\nğŸ“„ HTML guardado en: debug_computrabajo.html")
                
                if len(jobs1) == 0 and len(jobs2) == 0:
                    print(f"\nâš ï¸ PROBLEMA: No se encontraron ofertas")
                    return False
                
                return True
            
            else:
                print(f"\nâŒ Error HTTP: {response.status_code}")
                return False
        
        except Exception as e:
            print(f"âŒ ERROR: {e}")
            return False


# ============================================================================
# PUNTO DE ENTRADA
# ============================================================================

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘   JOB MONITOR - MODO DEBUG/PRUEBA    â•‘
    â•‘  DiagnÃ³stico de scraping             â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("\nâš™ï¸  Inicializando...\n")
    
    # Pedir tÃ­tulo de bÃºsqueda
    titulo = input("Ingresa el tÃ­tulo a buscar (ej: 'backend remote'): ").strip()
    
    if not titulo:
        titulo = "backend remote java"
        print(f"âš ï¸  Usando bÃºsqueda por defecto: '{titulo}'")
    
    print(f"\nâœ… Testearemos con: '{titulo}'\n")
    
    # Crear debugger
    debugger = DebugScraper()
    
    # Preguntar quÃ© portal probar
    print("Â¿CuÃ¡l portal quieres probar?")
    print("1ï¸âƒ£  Indeed")
    print("2ï¸âƒ£  InfoJobs")
    print("3ï¸âƒ£  Computrabajo")
    print("4ï¸âƒ£  Todos\n")
    
    opcion = input("Tu opciÃ³n (1-4): ").strip()
    
    resultados = {}
    
    if opcion in ["1", "4"]:
        resultados["Indeed"] = debugger.test_indeed(titulo)
    
    if opcion in ["2", "4"]:
        resultados["InfoJobs"] = debugger.test_infojobs(titulo)
    
    if opcion in ["3", "4"]:
        resultados["Computrabajo"] = debugger.test_computrabajo(titulo)
    
    # Resumen
    print("\n" + "="*70)
    print("ğŸ“Š RESUMEN")
    print("="*70 + "\n")
    
    for portal, resultado in resultados.items():
        estado = "âœ… OK" if resultado else "âŒ PROBLEMA"
        print(f"{portal:15} {estado}")
    
    print("\n" + "="*70)
    print("â„¹ï¸  Si algÃºn portal tiene PROBLEMA:")
    print("  1. Revisa el archivo debug_[portal].html")
    print("  2. Abre con tu navegador para ver quÃ© muestra")
    print("  3. El HTML guardado contiene los primeros 5000 caracteres")
    print("="*70 + "\n")
    
    # Soluciones
    print("ğŸ”§ SOLUCIONES POSIBLES:\n")
    print("Si NINGÃšN portal funciona:")
    print("  âŒ Problem: Indeed/InfoJobs pueden estar bloqueando")
    print("  âœ… SoluciÃ³n: Usar Selenium (requiere navegador)")
    print("\nSi funciona al menos UNO:")
    print("  âœ… Â¡El scraping SÃ funciona!")
    print("  âœ… Los selectores CSS pueden haber cambiado")
    print("  âœ… SoluciÃ³n: Actualizar selectores en el cÃ³digo\n")