"""
JOB MONITOR - VERSI√ìN DEBUG
Prueba de scraping con informaci√≥n detallada
"""

import requests
from bs4 import BeautifulSoup
from datetime import datetime

# ============================================================================
# HERRAMIENTAS DE DEBUG
# ============================================================================

class DebugScraper:
    """Scraper con informaci√≥n detallada para debugging"""
    
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    
    def test_indeed(self, titulo_busqueda):
        """Prueba Indeed con informaci√≥n detallada"""
        print("\n" + "="*70)
        print(f"üß™ PROBANDO INDEED")
        print("="*70 + "\n")
        
        try:
            url = "https://es.indeed.com/jobs"
            parametros = {
                "q": titulo_busqueda,
                "l": "Spain",
                "radius": "0",
                "jt": "fulltime"
            }
            
            print(f"üìç URL base: {url}")
            print(f"üîç Par√°metros:")
            for key, value in parametros.items():
                print(f"   ‚Ä¢ {key}: {value}")
            
            print(f"\nüì§ Enviando petici√≥n...\n")
            
            response = requests.get(
                url,
                params=parametros,
                headers=self.headers,
                timeout=10
            )
            
            print(f"üì• Respuesta recibida:")
            print(f"   ‚Ä¢ Status Code: {response.status_code}")
            print(f"   ‚Ä¢ Content-Type: {response.headers.get('content-type', 'N/A')}")
            print(f"   ‚Ä¢ Tama√±o: {len(response.content)} bytes")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, "html.parser")
                
                # Buscar diferentes selectores
                print(f"\nüîé Buscando ofertas con diferentes selectores:\n")
                
                # Selector 1
                jobs1 = soup.find_all("div", class_="job_seen_beacon")
                print(f"   ‚Ä¢ Selector 1 (job_seen_beacon): {len(jobs1)} resultados")
                
                # Selector 2
                jobs2 = soup.find_all("div", class_="job-tile")
                print(f"   ‚Ä¢ Selector 2 (job-tile): {len(jobs2)} resultados")
                
                # Selector 3
                jobs3 = soup.find_all("article")
                print(f"   ‚Ä¢ Selector 3 (article): {len(jobs3)} resultados")
                
                # Selector 4
                jobs4 = soup.find_all("li", class_="css-5lfssm")
                print(f"   ‚Ä¢ Selector 4 (li css-5lfssm): {len(jobs4)} resultados")
                
                # Buscar todos los divs con clase que contenga "job"
                jobs_all = soup.find_all("div", class_=lambda x: x and "job" in x.lower())
                print(f"   ‚Ä¢ Selector gen√©rico (contiene 'job'): {len(jobs_all)} resultados")
                
                # Guardar HTML para inspecci√≥n
                with open("debug_indeed.html", "w", encoding="utf-8") as f:
                    f.write(response.text[:5000])  # Primeros 5000 caracteres
                print(f"\nüìÑ HTML guardado en: debug_indeed.html")
                
                # Mostrar estructura b√°sica
                print(f"\nüèóÔ∏è Estructura de la p√°gina:")
                title = soup.find("title")
                print(f"   ‚Ä¢ T√≠tulo: {title.text if title else 'N/A'}")
                
                h1 = soup.find("h1")
                print(f"   ‚Ä¢ H1: {h1.text if h1 else 'N/A'}")
                
                # Verificar si hay errores/bloques
                if "Please enable javascript" in response.text or "Enable JavaScript" in response.text:
                    print(f"\n‚ö†Ô∏è PROBLEMA: Indeed requiere JavaScript")
                    print(f"   Soluci√≥n: Usar Selenium o API alternativa")
                    return False
                
                if response.status_code == 403:
                    print(f"\n‚ö†Ô∏è PROBLEMA: Acceso denegado (403)")
                    print(f"   Soluci√≥n: Indeed bloquea este User-Agent")
                    return False
                
                if len(jobs1) == 0 and len(jobs2) == 0 and len(jobs3) == 0:
                    print(f"\n‚ö†Ô∏è PROBLEMA: No se encontraron ofertas")
                    print(f"   Posibles causas:")
                    print(f"   1. Los selectores CSS han cambiado")
                    print(f"   2. Indeed bloque√≥ la petici√≥n")
                    print(f"   3. No hay ofertas para esta b√∫squeda")
                    return False
                
                return True
            
            else:
                print(f"\n‚ùå Error HTTP: {response.status_code}")
                if response.status_code == 403:
                    print("   Soluci√≥n: Aumentar delay o cambiar headers")
                elif response.status_code == 429:
                    print("   Soluci√≥n: Too many requests, esperar m√°s tiempo")
                return False
        
        except requests.exceptions.Timeout:
            print(f"‚ùå ERROR: Timeout (conexi√≥n muy lenta)")
            return False
        except Exception as e:
            print(f"‚ùå ERROR: {e}")
            return False
    
    def test_infojobs(self, titulo_busqueda):
        """Prueba InfoJobs con informaci√≥n detallada"""
        print("\n" + "="*70)
        print(f"üß™ PROBANDO INFOJOBS")
        print("="*70 + "\n")
        
        try:
            url = "https://www.infojobs.net/search"
            parametros = {
                "q": titulo_busqueda,
                "c": "47"
            }
            
            print(f"üìç URL base: {url}")
            print(f"üîç Par√°metros:")
            for key, value in parametros.items():
                print(f"   ‚Ä¢ {key}: {value}")
            
            print(f"\nüì§ Enviando petici√≥n...\n")
            
            response = requests.get(
                url,
                params=parametros,
                headers=self.headers,
                timeout=10
            )
            
            print(f"üì• Respuesta recibida:")
            print(f"   ‚Ä¢ Status Code: {response.status_code}")
            print(f"   ‚Ä¢ Tama√±o: {len(response.content)} bytes")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, "html.parser")
                
                print(f"\nüîé Buscando ofertas:\n")
                
                # Selector 1
                jobs1 = soup.find_all("article", class_="offer")
                print(f"   ‚Ä¢ Selector 1 (article.offer): {len(jobs1)} resultados")
                
                # Selector 2
                jobs2 = soup.find_all("div", class_="offer")
                print(f"   ‚Ä¢ Selector 2 (div.offer): {len(jobs2)} resultados")
                
                # Selector 3
                jobs3 = soup.find_all("article")
                print(f"   ‚Ä¢ Selector 3 (article gen√©rico): {len(jobs3)} resultados")
                
                # Guardar HTML
                with open("debug_infojobs.html", "w", encoding="utf-8") as f:
                    f.write(response.text[:5000])
                print(f"\nüìÑ HTML guardado en: debug_infojobs.html")
                
                if len(jobs1) == 0 and len(jobs2) == 0:
                    print(f"\n‚ö†Ô∏è PROBLEMA: No se encontraron ofertas")
                    return False
                
                return True
            
            else:
                print(f"\n‚ùå Error HTTP: {response.status_code}")
                return False
        
        except Exception as e:
            print(f"‚ùå ERROR: {e}")
            return False
    
    def test_computrabajo(self, titulo_busqueda):
        """Prueba Computrabajo con informaci√≥n detallada"""
        print("\n" + "="*70)
        print(f"üß™ PROBANDO COMPUTRABAJO")
        print("="*70 + "\n")
        
        try:
            url = "https://www.computrabajo.com/search/jobs"
            parametros = {
                "q": titulo_busqueda,
                "location": "Spain"
            }
            
            print(f"üìç URL base: {url}")
            print(f"üîç Par√°metros:")
            for key, value in parametros.items():
                print(f"   ‚Ä¢ {key}: {value}")
            
            print(f"\nüì§ Enviando petici√≥n...\n")
            
            response = requests.get(
                url,
                params=parametros,
                headers=self.headers,
                timeout=10
            )
            
            print(f"üì• Respuesta recibida:")
            print(f"   ‚Ä¢ Status Code: {response.status_code}")
            print(f"   ‚Ä¢ Tama√±o: {len(response.content)} bytes")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, "html.parser")
                
                print(f"\nüîé Buscando ofertas:\n")
                
                # Selector 1
                jobs1 = soup.find_all("div", class_="offer-item")
                print(f"   ‚Ä¢ Selector 1 (offer-item): {len(jobs1)} resultados")
                
                # Selector 2
                jobs2 = soup.find_all("div", class_="job")
                print(f"   ‚Ä¢ Selector 2 (job): {len(jobs2)} resultados")
                
                # Guardar HTML
                with open("debug_computrabajo.html", "w", encoding="utf-8") as f:
                    f.write(response.text[:5000])
                print(f"\nüìÑ HTML guardado en: debug_computrabajo.html")
                
                if len(jobs1) == 0 and len(jobs2) == 0:
                    print(f"\n‚ö†Ô∏è PROBLEMA: No se encontraron ofertas")
                    return False
                
                return True
            
            else:
                print(f"\n‚ùå Error HTTP: {response.status_code}")
                return False
        
        except Exception as e:
            print(f"‚ùå ERROR: {e}")
            return False


# ============================================================================
# PUNTO DE ENTRADA
# ============================================================================

if __name__ == "__main__":
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë   JOB MONITOR - MODO DEBUG/PRUEBA    ‚ïë
    ‚ïë  Diagn√≥stico de scraping             ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    print("\n‚öôÔ∏è  Inicializando...\n")
    
    # Pedir t√≠tulo de b√∫squeda
    titulo = input("Ingresa el t√≠tulo a buscar (ej: 'backend remote'): ").strip()
    
    if not titulo:
        titulo = "backend remote java"
        print(f"‚ö†Ô∏è  Usando b√∫squeda por defecto: '{titulo}'")
    
    print(f"\n‚úÖ Testearemos con: '{titulo}'\n")
    
    # Crear debugger
    debugger = DebugScraper()
    
    # Preguntar qu√© portal probar
    print("¬øCu√°l portal quieres probar?")
    print("1Ô∏è‚É£  Indeed")
    print("2Ô∏è‚É£  InfoJobs")
    print("3Ô∏è‚É£  Computrabajo")
    print("4Ô∏è‚É£  Todos\n")
    
    opcion = input("Tu opci√≥n (1-4): ").strip()
    
    resultados = {}
    
    if opcion in ["1", "4"]:
        resultados["Indeed"] = debugger.test_indeed(titulo)
    
    if opcion in ["2", "4"]:
        resultados["InfoJobs"] = debugger.test_infojobs(titulo)
    
    if opcion in ["3", "4"]:
        resultados["Computrabajo"] = debugger.test_computrabajo(titulo)
    
    # Resumen
    print("\n" + "="*70)
    print("üìä RESUMEN")
    print("="*70 + "\n")
    
    for portal, resultado in resultados.items():
        estado = "‚úÖ OK" if resultado else "‚ùå PROBLEMA"
        print(f"{portal:15} {estado}")
    
    print("\n" + "="*70)
    print("‚ÑπÔ∏è  Si alg√∫n portal tiene PROBLEMA:")
    print("  1. Revisa el archivo debug_[portal].html")
    print("  2. Abre con tu navegador para ver qu√© muestra")
    print("  3. El HTML guardado contiene los primeros 5000 caracteres")
    print("="*70 + "\n")
    
    # Soluciones
    print("üîß SOLUCIONES POSIBLES:\n")
    print("Si NING√öN portal funciona:")
    print("  ‚ùå Problem: Indeed/InfoJobs pueden estar bloqueando")
    print("  ‚úÖ Soluci√≥n: Usar Selenium (requiere navegador)")
    print("\nSi funciona al menos UNO:")
    print("  ‚úÖ ¬°El scraping S√ç funciona!")
    print("  ‚úÖ Los selectores CSS pueden haber cambiado")
    print("  ‚úÖ Soluci√≥n: Actualizar selectores en el c√≥digo\n")